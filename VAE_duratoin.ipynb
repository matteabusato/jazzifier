{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset and Definition of Useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_parse_all_columns_df(df):\n",
    "    \"\"\"\n",
    "    Parse all columns in a DataFrame to numeric, coercing errors.\n",
    "    \"\"\"\n",
    "    df['notes'] = df['notes'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['chords'] = df['chords'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['velocities'] = df['velocities'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['durations'] = df['durations'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['offsets'] = df['offsets'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    df['ordered_events'] = df['ordered_events'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "def load_dataframe_from_two_csvs(file1, file2):\n",
    "    \"\"\"\n",
    "    Load and concatenate two CSV files into a single pandas DataFrame.\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    full_df = pd.concat([df1, df2], ignore_index=True)\n",
    "    full_df = safe_parse_all_columns_df(full_df)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "def save_dataframe_to_two_csvs(df, file1, file2):\n",
    "    \"\"\"\n",
    "    Split a DataFrame in half and save it into two CSV files.\n",
    "    \"\"\"\n",
    "    halfway = len(df) // 2\n",
    "    df.iloc[:halfway].to_csv(file1, index=False)\n",
    "    df.iloc[halfway:].to_csv(file2, index=False)\n",
    "\n",
    "def load_dataframe_from_one_csv(file):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from a single CSV file.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def save_dataframe_to_one_csv(df, file):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a single CSV file.\n",
    "    \"\"\"\n",
    "    df.to_csv(file, index=True)\n",
    "\n",
    "def load_reconstructed_events(file):\n",
    "    \"\"\"\n",
    "    Loads the reconstructed events CSV and safely parses the 'sequence' column,\n",
    "    converting notes to integers and chords to lists of integers.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    def safe_parse(seq_str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(seq_str)\n",
    "            if not isinstance(parsed, list):\n",
    "                raise ValueError(\"Parsed sequence is not a list\")\n",
    "\n",
    "            normalized = []\n",
    "            for el in parsed:\n",
    "                if isinstance(el, list):\n",
    "                    normalized.append([int(x) for x in el])\n",
    "                else:\n",
    "                    normalized.append(int(el))\n",
    "            return normalized\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing sequence: {seq_str}\")\n",
    "            raise e\n",
    "\n",
    "    df['sequence'] = df['sequence'].apply(safe_parse)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'data_processed/'\n",
    "file1 = root + 'data_part1.csv'\n",
    "file2 = root + 'data_part2.csv'\n",
    "\n",
    "df = load_dataframe_from_two_csvs(file1, file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chord_to_list(chord):\n",
    "    \"\"\"\n",
    "    Convert a chord string to a list of integers.\n",
    "    \"\"\"\n",
    "    if isinstance(chord, str):\n",
    "        print([int(x) for x in chord.split(',') if x.isdigit()])\n",
    "        return [int(x) for x in chord.split(',') if x.isdigit()]\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_ordered_events(df):\n",
    "    \"\"\"\n",
    "    Reconstruct the ordered list of events (notes and chords) for each song.\n",
    "    \"\"\"\n",
    "    sequences  = []\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        idx_note = 0\n",
    "        idx_chord = 0\n",
    "        reconstructed = []\n",
    "\n",
    "        for element in df['ordered_events'][i]:\n",
    "            if element == 'n':\n",
    "                reconstructed.append(df['notes'][i][idx_note])\n",
    "                idx_note += 1\n",
    "            elif element == 'c':\n",
    "                parsed_chord = parse_chord_to_list(df['chords'][i][idx_chord])\n",
    "                reconstructed.append(df['chords'][i][idx_chord])\n",
    "                idx_chord += 1\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown event type: {e}\")\n",
    "        \n",
    "        sequences.append(reconstructed)\n",
    "\n",
    "    reconstructed_dataset = pd.DataFrame({'sequence': sequences})\n",
    "    reconstructed_dataset.index.name = 'index'\n",
    "\n",
    "    return reconstructed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe_to_one_csv(reconstruct_ordered_events(df), root + 'reconstructed_ordered_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict only Events (Notes and Chords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the data: Fixed number of events "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for creating the input sequences:\n",
    "- we take subsets of the list of events representing each song \n",
    "- we take the next event of each subset as corresponding training output sequences\n",
    "\n",
    "This is easy to implement and we will have a consistent sequence lenght for batching, but we are ignoring the timing aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, reconstructed_df):\n",
    "        \"\"\"\n",
    "        Build vocabulary of unique single notes only.\n",
    "        \"\"\"\n",
    "        self.notes = set()\n",
    "        for i in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][i]\n",
    "            for event in sequence:\n",
    "                if isinstance(event, list):\n",
    "                    for note in event:\n",
    "                        self.notes.add(note)\n",
    "                else:\n",
    "                    self.notes.add(event)\n",
    "\n",
    "        self.notes = sorted(self.notes)\n",
    "        self.note_to_idx = {note: idx for idx, note in enumerate(self.notes)}\n",
    "        self.idx_to_note = {idx: note for idx, note in enumerate(self.notes)}\n",
    "        self.vocab_size = len(self.notes)\n",
    "\n",
    "    def encode_event(self, event):\n",
    "        \"\"\"\n",
    "        Encode an event as a multi-hot vector over single notes.\n",
    "        \"\"\"\n",
    "        vec = np.zeros(self.vocab_size, dtype=np.float32)\n",
    "        if isinstance(event, list):\n",
    "            for note in event:\n",
    "                vec[self.note_to_idx[note]] = 1.0\n",
    "        else:\n",
    "            vec[self.note_to_idx[event]] = 1.0\n",
    "        return vec\n",
    "\n",
    "    def decode_event(self, vec, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Decode multi-hot vector to list of notes.\n",
    "        \"\"\"\n",
    "        indices = np.where(vec >= threshold)[0]\n",
    "        notes = [self.idx_to_note[idx] for idx in indices]\n",
    "        if len(notes) == 1:\n",
    "            return notes[0]\n",
    "        else:\n",
    "            return notes\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEventDataset(Dataset):\n",
    "    def __init__(self, reconstructed_df, vocab, seq_length=50):\n",
    "        \"\"\"\n",
    "        Constructs all valid (input_seq, target_event) pairs from each song in the dataset.\n",
    "\n",
    "        Args:\n",
    "            reconstructed_df: DataFrame with 'sequence' column where each entry is a list of events\n",
    "            vocab: Vocabulary object to encode events\n",
    "            seq_length: Length of each training input sequence (target is the next event)\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab = vocab\n",
    "\n",
    "        for row_index in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][row_index]\n",
    "            n_events = len(sequence)\n",
    "\n",
    "            if n_events <= seq_length:\n",
    "                continue\n",
    "\n",
    "            for i in range(n_events - seq_length):\n",
    "                input_seq = sequence[i : i + seq_length]\n",
    "                target_event = sequence[i + seq_length]\n",
    "                self.samples.append((input_seq, target_event))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, target_event = self.samples[idx]\n",
    "\n",
    "        input_encoded = np.array([self.vocab.encode_event(event) for event in input_seq], dtype=np.float32)\n",
    "        input_tensor = torch.tensor(input_encoded)\n",
    "\n",
    "        target_encoded = self.vocab.encode_event(target_event)\n",
    "        target_tensor = torch.tensor(target_encoded, dtype=torch.float32)\n",
    "\n",
    "        return input_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence shape: torch.Size([16, 88])\n",
      "Next event shape: torch.Size([88])\n",
      "Input sequence (multi-hot vectors): tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Next event (multi-hot vector): tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "reconstructed_dataset = load_reconstructed_events(root + 'reconstructed_ordered_events.csv')\n",
    "\n",
    "vocab = Vocabulary(reconstructed_dataset)\n",
    "\n",
    "dataset = MusicEventDataset(reconstructed_dataset, vocab=vocab, seq_length=16)\n",
    "\n",
    "x, y = dataset[0]\n",
    "\n",
    "print(\"Input sequence shape:\", x.shape)\n",
    "print(\"Next event shape:\", y.shape)\n",
    "print(\"Input sequence (multi-hot vectors):\", x)\n",
    "print(\"Next event (multi-hot vector):\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicEventDataset(Dataset):\n",
    "    def __init__(self, reconstructed_df, vocab, seq_length=50):\n",
    "        self.samples = []\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab = vocab\n",
    "\n",
    "        for row_index in range(len(reconstructed_df)):\n",
    "            sequence = reconstructed_df['sequence'][row_index]\n",
    "            durations = reconstructed_df['durations'][row_index]  # durations list per song\n",
    "            assert len(sequence) == len(durations)\n",
    "\n",
    "            n_events = len(sequence)\n",
    "            if n_events <= seq_length:\n",
    "                continue\n",
    "\n",
    "            for i in range(n_events - seq_length):\n",
    "                input_seq = sequence[i : i + seq_length]\n",
    "                input_dur = durations[i : i + seq_length]\n",
    "                target_event = sequence[i + seq_length]\n",
    "                target_dur = durations[i + seq_length]\n",
    "                self.samples.append((input_seq, input_dur, target_event, target_dur))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_seq, input_dur, target_event, target_dur = self.samples[idx]\n",
    "\n",
    "        input_notes_encoded = np.array([self.vocab.encode_event(ev) for ev in input_seq], dtype=np.float32)\n",
    "        input_durs_encoded = np.array(input_dur, dtype=np.float32).reshape(-1, 1)\n",
    "\n",
    "        input_tensor = torch.tensor(np.hstack((input_notes_encoded, input_durs_encoded)))  # concat per timestep\n",
    "        target_notes_tensor = torch.tensor(self.vocab.encode_event(target_event), dtype=torch.float32)\n",
    "        target_dur_tensor = torch.tensor(target_dur, dtype=torch.float32)\n",
    "\n",
    "        return input_tensor, target_notes_tensor, target_dur_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicVAE(nn.Module):\n",
    "    def __init__(self, input_dim_notes, hidden_dim=256, latent_dim=64, seq_length=16):\n",
    "        super(MusicVAE, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.input_dim_notes = input_dim_notes\n",
    "        self.input_dim_total = input_dim_notes + 1  # +1 for duration\n",
    "\n",
    "        self.encoder_rnn = nn.GRU(self.input_dim_total, hidden_dim, batch_first=True)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self.decoder_input = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.decoder_rnn = nn.GRU(self.input_dim_total, hidden_dim, batch_first=True)\n",
    "        self.decoder_output_notes = nn.Linear(hidden_dim, input_dim_notes)\n",
    "        self.decoder_output_dur = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        _, h = self.encoder_rnn(x)\n",
    "        h = h.squeeze(0)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, seq_length):\n",
    "        batch_size = z.size(0)\n",
    "        h0 = self.decoder_input(z).unsqueeze(0)\n",
    "\n",
    "        x = torch.zeros((batch_size, 1, self.input_dim_total), device=z.device)\n",
    "        notes_out = []\n",
    "        durs_out = []\n",
    "\n",
    "        for _ in range(seq_length):\n",
    "            out, h0 = self.decoder_rnn(x, h0)\n",
    "            note_step = self.decoder_output_notes(out)\n",
    "            dur_step = self.decoder_output_dur(out)\n",
    "\n",
    "            notes_out.append(note_step)\n",
    "            durs_out.append(dur_step)\n",
    "\n",
    "            # Feed output back into next step\n",
    "            x = torch.cat([torch.sigmoid(note_step), dur_step], dim=2).detach()\n",
    "\n",
    "        notes_out = torch.cat(notes_out, dim=1)\n",
    "        durs_out = torch.cat(durs_out, dim=1)\n",
    "        return notes_out, durs_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        notes_out, durs_out = self.decode(z, self.seq_length)\n",
    "        return notes_out, durs_out, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(notes_pred, durs_pred, notes_true, durs_true, mu, logvar):\n",
    "    note_loss = F.binary_cross_entropy_with_logits(notes_pred, notes_true, reduction='sum')\n",
    "    dur_loss = F.mse_loss(durs_pred, durs_true, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return note_loss + dur_loss + kl_div\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event: 88\n",
      "Encoded: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "event = reconstructed_dataset['sequence'][0][0]\n",
    "encoding = vocab.encode_event(event)\n",
    "print(\"Event:\", event)\n",
    "print(\"Encoded:\", encoding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load parts with durations\n",
    "part1 = pd.read_csv(\"data_processed/data_part1.csv\")\n",
    "part2 = pd.read_csv(\"data_processed/data_part2.csv\")\n",
    "\n",
    "# Merge them vertically\n",
    "duration_df = pd.concat([part1, part2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences: 2775\n",
      "Durations: 2775\n",
      "Seq 0 = 2429, Dur = 2429\n",
      "Seq 1 = 1813, Dur = 1813\n",
      "Seq 2 = 1248, Dur = 1248\n",
      "Seq 3 = 1379, Dur = 1379\n",
      "Seq 4 = 1357, Dur = 1357\n"
     ]
    }
   ],
   "source": [
    "print(\"Sequences:\", len(reconstructed_dataset))\n",
    "print(\"Durations:\", len(duration_df))\n",
    "\n",
    "# Optional: check a few row lengths\n",
    "for i in range(5):\n",
    "    print(f\"Seq {i} = {len((reconstructed_dataset['sequence'][i]))}, Dur = {len(eval(duration_df['durations'][i]))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def safe_eval_list(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Error parsing:\", x)\n",
    "        return None  # or [] if you want to skip it entirely\n",
    "\n",
    "# Load CSVs\n",
    "reconstructed_df = pd.read_csv(\"data_processed/reconstructed_ordered_events.csv\")\n",
    "part1 = pd.read_csv(\"data_processed/data_part1.csv\")\n",
    "part2 = pd.read_csv(\"data_processed/data_part2.csv\")\n",
    "duration_df = pd.concat([part1, part2], ignore_index=True)\n",
    "\n",
    "# Apply safe parsing\n",
    "reconstructed_df['sequence'] = reconstructed_df['sequence'].apply(safe_eval_list)\n",
    "duration_df['durations'] = duration_df['durations'].apply(safe_eval_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = reconstructed_dataset.copy()\n",
    "combined_df['durations'] = duration_df['durations']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"data_processed/reconstructed_with_durations.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq, durs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdurations\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Convert from string to Python object if needed\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 21\u001b[0m         seq \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(durs, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     23\u001b[0m         durs \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(durs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:66\u001b[0m, in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03mEvaluate an expression node or a string containing only a Python\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mexpression.  The string or node provided may only consist of the following\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03mCaution: A complex expression can overflow the C stack and cause a crash.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node_or_string, Expression):\n\u001b[1;32m     68\u001b[0m     node_or_string \u001b[38;5;241m=\u001b[39m node_or_string\u001b[38;5;241m.\u001b[39mbody\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/ast.py:52\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(source, filename, mode, type_comments, feature_version)\u001b[0m\n\u001b[1;32m     50\u001b[0m     feature_version \u001b[38;5;241m=\u001b[39m minor\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Else it should be an int giving the minor version for 3.x.\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m               \u001b[49m\u001b[43m_feature_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_version\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Load the dataframe\n",
    "df = pd.read_csv(\"data_processed/reconstructed_with_durations.csv\")\n",
    "\n",
    "# Helper function to convert events to string tokens\n",
    "def tokenize_event_duration(event, duration):\n",
    "    if isinstance(event, list):\n",
    "        event_token = \"-\".join(map(str, sorted(event)))\n",
    "    else:\n",
    "        event_token = str(event)\n",
    "    return f\"{event_token}_{duration}\"\n",
    "\n",
    "# Tokenize all sequences\n",
    "tokenized_sequences = []\n",
    "\n",
    "for seq, durs in zip(df['sequence'], df['durations']):\n",
    "    # Convert from string to Python object if needed\n",
    "    if isinstance(seq, str):\n",
    "        seq = ast.literal_eval(seq)\n",
    "    if isinstance(durs, str):\n",
    "        durs = ast.literal_eval(durs)\n",
    "        \n",
    "    assert len(seq) == len(durs), \"Mismatch between sequence and durations length\"\n",
    "    \n",
    "    tokens = [tokenize_event_duration(e, d) for e, d in zip(seq, durs)]\n",
    "    tokenized_sequences.append(tokens)\n",
    "\n",
    "# Add to dataframe\n",
    "df['tokenized'] = tokenized_sequences\n",
    "\n",
    "# Save or inspect\n",
    "df[['index', 'tokenized']].to_csv(\"data_processed/tokenized_sequences.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 430169\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"data_processed/reconstructed_with_durations.csv\")\n",
    "\n",
    "def tokenize_event_duration(event, duration):\n",
    "    if isinstance(event, list):\n",
    "        event_token = \"-\".join(map(str, sorted(event)))\n",
    "    else:\n",
    "        event_token = str(event)\n",
    "    return f\"{event_token}_{duration}\"\n",
    "\n",
    "all_tokens = set()\n",
    "\n",
    "for seq, durs in zip(df['sequence'], df['durations']):\n",
    "    seq = ast.literal_eval(seq)\n",
    "    durs = ast.literal_eval(durs)\n",
    "    tokens = [tokenize_event_duration(e, d) for e, d in zip(seq, durs)]\n",
    "    all_tokens.update(tokens)\n",
    "\n",
    "print(\"Number of unique tokens:\", len(all_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-31 13:38:07.431525: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load tokenized sequence CSV\n",
    "df = pd.read_csv(\"data_processed/tokenized_sequences.csv\")\n",
    "\n",
    "# Parse the stringified lists\n",
    "df[\"tokenized\"] = df[\"tokenized\"].apply(ast.literal_eval)\n",
    "\n",
    "# Flatten and count token frequencies (optional)\n",
    "all_tokens = [token for seq in df[\"tokenized\"] for token in seq]\n",
    "token_freq = Counter(all_tokens)\n",
    "\n",
    "# Create vocab: token -> index\n",
    "vocab = {token: idx + 1 for idx, token in enumerate(sorted(token_freq))}  # Reserve 0 for padding\n",
    "vocab[\"<PAD>\"] = 0\n",
    "inv_vocab = {i: t for t, i in vocab.items()}\n",
    "\n",
    "# Encode sequences\n",
    "encoded_sequences = [[vocab[token] for token in seq] for seq in df[\"tokenized\"]]\n",
    "\n",
    "# Pad sequences to fixed length\n",
    "seq_length = 50\n",
    "padded_sequences = pad_sequences(encoded_sequences, maxlen=seq_length, padding='post', truncating='post')\n",
    "\n",
    "# Convert to numpy array\n",
    "import numpy as np\n",
    "x_train = np.array(padded_sequences)\n",
    "\n",
    "# Save vocab if needed\n",
    "import json\n",
    "with open(\"data_processed/vocab.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430170"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# ======== VAE LOSS ========\u001b[39;00m\n\u001b[1;32m     42\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39msparse_categorical_crossentropy(encoder_inputs, vae_outputs)\n\u001b[0;32m---> 43\u001b[0m reconstruction_loss \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreconstruction_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m kl_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m K\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m z_log_var \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39msquare(z_mean) \u001b[38;5;241m-\u001b[39m K\u001b[38;5;241m.\u001b[39mexp(z_log_var), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     47\u001b[0m vae_loss \u001b[38;5;241m=\u001b[39m K\u001b[38;5;241m.\u001b[39mmean(reconstruction_loss \u001b[38;5;241m+\u001b[39m kl_loss)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/legacy/backend.py:2112\u001b[0m, in \u001b[0;36msum\u001b[0;34m(x, axis, keepdims)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras._legacy.backend.sum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"DEPRECATED.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/ops/weak_tensor_ops.py:88\u001b[0m, in \u001b[0;36mweak_tensor_unary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/backend/common/keras_tensor.py:91\u001b[0m, in \u001b[0;36mKerasTensor.__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor cannot be used as input to a TensorFlow function. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA KerasTensor is a symbolic placeholder for a shape and dtype, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused when constructing Keras Functional models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor Keras Functions. You can only use it as input to a Keras layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor a Keras operation (from the namespaces `keras.layers` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `keras.operations`). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are likely doing something like:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = Input(...)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_fn(x)  # Invalid.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat you should do instead is wrap `tf_fn` in a layer:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass MyLayer(Layer):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    def call(self, x):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m        return tf_fn(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx = MyLayer()(x)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Reshape, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Parameters\n",
    "vocab_size = len(vocab)            # total number of unique token IDs\n",
    "print(vocab_size)\n",
    "embedding_dim = 128                # dimension of token embedding\n",
    "seq_length = 50                    # length of input sequences\n",
    "latent_dim = 32                    # size of latent space\n",
    "\n",
    "# ======== ENCODER ========\n",
    "encoder_inputs = Input(shape=(seq_length,), name=\"encoder_input\")\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length)(encoder_inputs)\n",
    "flatten = Flatten()(embedding_layer)\n",
    "\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(flatten)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(flatten)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "# ======== DECODER ========\n",
    "decoder_inputs = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "decoder_dense = Dense(seq_length * embedding_dim, activation=\"relu\")(decoder_inputs)\n",
    "decoder_reshape = Reshape((seq_length, embedding_dim))(decoder_dense)\n",
    "decoder_output = Dense(vocab_size, activation=\"softmax\")(decoder_reshape)  # Predict token at each position\n",
    "\n",
    "# ======== MODELS ========\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "decoder = Model(decoder_inputs, decoder_output, name=\"decoder\")\n",
    "\n",
    "vae_outputs = decoder(encoder(encoder_inputs)[2])\n",
    "vae = Model(encoder_inputs, vae_outputs, name=\"vae\")\n",
    "\n",
    "# ======== VAE LOSS ========\n",
    "reconstruction_loss = tf.keras.losses.sparse_categorical_crossentropy(encoder_inputs, vae_outputs)\n",
    "reconstruction_loss = K.sum(reconstruction_loss, axis=1)\n",
    "\n",
    "kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=1)\n",
    "\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer=\"adam\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name=\"reconstruction_loss\")\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            data = data[0]  # discard labels if passed as (x, y)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "\n",
    "            # Compute reconstruction loss\n",
    "            reconstruction_loss = tf.reduce_sum(\n",
    "                sparse_categorical_crossentropy(data, reconstruction), axis=1\n",
    "            )\n",
    "\n",
    "            # Compute KL divergence\n",
    "            kl_loss = -0.5 * tf.reduce_sum(\n",
    "                1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1\n",
    "            )\n",
    "\n",
    "            total_loss = tf.reduce_mean(reconstruction_loss + kl_loss)\n",
    "\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=\"adam\")\n",
    "vae.fit(x_train, epochs=20, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# --- Model parameters\n",
    "vocab_size = len(vocab)        # your built vocabulary\n",
    "embedding_dim = 128\n",
    "seq_length = 50\n",
    "latent_dim = 32\n",
    "\n",
    "# --- Encoder\n",
    "encoder_inputs = Input(shape=(seq_length,), name=\"encoder_input\")\n",
    "x = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length)(encoder_inputs)\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, name=\"z\")([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Reshape, Dense, TimeDistributed, Softmax\n",
    "\n",
    "decoder_inputs = Input(shape=(latent_dim,), name=\"decoder_input\")\n",
    "x = Dense(seq_length * embedding_dim, activation=\"relu\")(decoder_inputs)\n",
    "x = Reshape((seq_length, embedding_dim))(x)\n",
    "x = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(x)  # Predict token probabilities\n",
    "\n",
    "decoder = Model(decoder_inputs, x, name=\"decoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=\"adam\")\n",
    "vae.fit(x_train, epochs=1, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast  # for safely evaluating stringified Python literals\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(\"data_processed/reconstructed_with_durations.csv\")\n",
    "\n",
    "# Convert string representations of lists into actual Python lists\n",
    "df[\"sequence\"] = df[\"sequence\"].apply(ast.literal_eval)\n",
    "df[\"durations\"] = df[\"durations\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique MIDI notes (not full chords)\n",
    "all_notes = set()\n",
    "for seq in combined_df[\"sequence\"]:\n",
    "    for item in seq:\n",
    "        if isinstance(item, list):\n",
    "            all_notes.update(item)\n",
    "        else:\n",
    "            all_notes.add(item)\n",
    "\n",
    "# Final sorted list of unique pitches\n",
    "sorted_notes = sorted(all_notes)\n",
    "note2idx = {note: i for i, note in enumerate(sorted_notes)}\n",
    "vocab_size = len(note2idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def encode_event(note_or_chord, duration):\n",
    "    note_vec = torch.zeros(vocab_size)\n",
    "    \n",
    "    if isinstance(note_or_chord, list):\n",
    "        for note in note_or_chord:\n",
    "            if note in note2idx:\n",
    "                note_vec[note2idx[note]] = 1\n",
    "    else:\n",
    "        if note_or_chord in note2idx:\n",
    "            note_vec[note2idx[note_or_chord]] = 1\n",
    "\n",
    "    duration_tensor = torch.tensor([float(duration)], dtype=torch.float)\n",
    "    return torch.cat([note_vec, duration_tensor])  # shape: (vocab_size + 1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MusicEventDataset(Dataset):\n",
    "    def __init__(self, dataframe, seq_length=50):\n",
    "        self.samples = []\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        for notes, durations in zip(dataframe[\"sequence\"], dataframe[\"durations\"]):\n",
    "            assert len(notes) == len(durations), \"Mismatch between notes and durations\"\n",
    "            if len(notes) <= seq_length:\n",
    "                continue\n",
    "            for i in range(len(notes) - seq_length):\n",
    "                input_seq = [\n",
    "                    encode_event(notes[j], durations[j])\n",
    "                    for j in range(i, i + seq_length)\n",
    "                ]\n",
    "                target = encode_event(notes[i + seq_length], durations[i + seq_length])\n",
    "                self.samples.append((torch.stack(input_seq), target))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMusicEventDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m      5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[35], line 14\u001b[0m, in \u001b[0;36mMusicEventDataset.__init__\u001b[0;34m(self, dataframe, seq_length)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(notes) \u001b[38;5;241m-\u001b[39m seq_length):\n\u001b[1;32m     13\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 14\u001b[0m         \u001b[43mencode_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnotes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m seq_length)\n\u001b[1;32m     16\u001b[0m     ]\n\u001b[1;32m     17\u001b[0m     target \u001b[38;5;241m=\u001b[39m encode_event(notes[i \u001b[38;5;241m+\u001b[39m seq_length], durations[i \u001b[38;5;241m+\u001b[39m seq_length])\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\u001b[38;5;241m.\u001b[39mappend((torch\u001b[38;5;241m.\u001b[39mstack(input_seq), target))\n",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m, in \u001b[0;36mencode_event\u001b[0;34m(note_or_chord, duration)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m note_or_chord \u001b[38;5;129;01min\u001b[39;00m note2idx:\n\u001b[1;32m     12\u001b[0m         note_vec[note2idx[note_or_chord]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 14\u001b[0m duration_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mduration\u001b[49m\u001b[43m)\u001b[49m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([note_vec, duration_tensor])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = MusicEventDataset(combined_df, seq_length=50)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
